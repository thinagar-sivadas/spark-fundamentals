{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, IntegerType, BooleanType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"spark_sql_app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "        [\n",
    "            StructField(\"date\", StringType(), True),\n",
    "            StructField(\"delay\", IntegerType(), True),\n",
    "            StructField(\"distance\", IntegerType(), True),\n",
    "            StructField(\"origin\", StringType(), True),\n",
    "            StructField(\"destination\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df = spark.read.format(\"csv\").schema(schema).option(\"header\", \"true\").load(\"/opt/bitnami/spark/custom_data/chapter4/departuredelays.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Create temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"us_delay_flights_tbl\")\n",
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT distance, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE distance > 1000\n",
    "ORDER BY distance DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date, distance, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE delay > 120 AND\n",
    "origin = 'SFO' and destination='ORD' \n",
    "ORDER BY delay DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT delay, origin, destination,\n",
    "CASE\n",
    "    WHEN delay>360 THEN 'Very Long Delays'\n",
    "    WHEN delay>=120 and delay<=360 THEN 'Long Delays'\n",
    "    WHEN delay>=60 and delay <120 THEN 'Short Delays'\n",
    "    WHEN delay>0 and delay<60 THEN  'Tolerable Delays'\n",
    "    WHEN delay=0 THEN 'No Delays'\n",
    "END as Flight_Delays\n",
    "FROM us_delay_flights_tbl\n",
    "ORDER BY origin, delay DESC\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# SQL databases and tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE DATABASE IF NOT EXISTS learn_spark_db\"\"\")\n",
    "spark.sql(\"\"\"use learn_spark_db\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Managed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS managed_us_delay_flights_tbl\"\"\")\n",
    "df.write.mode('overwrite').saveAsTable(\"managed_us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Unmanaged table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS unmanaged_us_delay_flights_tbl\"\"\")\n",
    "df.write.option(\"path\", \"/opt/bitnami/spark/custom_data/chapter4/output/\").mode('overwrite').saveAsTable(\"unmanaged_us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## View metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listColumns(\"unmanaged_us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = spark.table(\"us_delay_flights_tbl\")\n",
    "df_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
